---
layout: single
title: "War For Truth: Redefining Social Media in a Manipulated Age"
author: Jason Vanderburg
date: 2025-04-17
excerpt: "Social media and epistemic warfare."
permalink: /essays/war-for-truth/
---

**Jason Vanderburg**
*College Writing II*
*Dr. Uraina Pack*
*17 Apr 2025*

## War For Truth: Redefining Social Media in a Manipulated Age

Social media, defined as “forms of electronic communication (such as websites for social networking and microblogging) through which users create online communities to share information, ideas, personal messages, and other content (such as videos)” (Merriam-Webster Dictionary), was originally conceived as a tool for connection and communication. This literal definition captures what social media was meant to be: a digital town square where users shared experiences freely. However, in today’s reality, the platforms that dominate this space, such as Facebook, Instagram, TikTok, and X (formerly Twitter), have strayed far from that ideal. Earlier communication technologies—such as radio, newspapers, and even television—functioned primarily as one-way channels of information, often regulated by broadcast standards or journalistic ethics. Social media, by contrast, combines participatory publishing with invisible algorithmic curation, blurring the line between user and broadcaster. This shift introduces unprecedented complexity into how information is spread, consumed, and trusted. Tarleton Gillespie, a Principal Researcher at Microsoft Research and an Adjunct Associate Professor at Cornell University, observes in Custodians of the Internet, “it takes a while— years, decades— for a culture to adjust itself to the subtle workings of a new information system, and to stop expecting from it what traditional systems provided” (Gillespie 42). This shift, not only in the size and prominence of social media platforms but also in their underlying purpose and practices, demands a full reconsideration of what “social media” means today. Social media today is more than a communication tool; it has become a mechanism for surveillance, behavioral manipulation, and the spread of misinformation, often orchestrated by corporate interests. True social media, by its original definition, would empower users with open, unfiltered communication rather than monetize attention spans and control discourse. Regulation is necessary to address corporate abuses; however, it alone cannot restore truth to a system designed for manipulation. Without the emergence of strong independent forces dedicated to transparency, society remains locked in an ongoing war for reality itself. While regulation may slow the harm caused by corporate social media platforms, meaningful resistance requires a cultural awakening that current systems of education and governance are ill-equipped to provide.

### Corporate Control and Manipulation

The centralization of social media platforms has transformed them from neutral tools of communication into powerful engines of manipulation, where corporate interests control what information users see and believe. Unlike early communication technologies, such as the telephone or the printing press, today’s dominant platforms like Facebook, TikTok, and X use algorithmic systems not simply to share information but to curate and amplify content that maximizes user engagement — often favoring outrage, fear, and disinformation. Management scholars Katherine C. Kellogg, Melissa Valentine, and Angèle Christin explain that social media platforms exert control through six algorithmic mechanisms — restriction, recommendation, recording, rating, replacing, and rewarding — which allow corporations to invisibly shape user behavior and interactions to maximize profitability (Kellogg et al.). This commercial incentive fosters an environment where truth becomes secondary to profitability. Tarleton Gillespie emphasizes that platforms are no longer passive hosts but active “custodians” who shape public discourse by selectively moderating and promoting content to align with business interests (Gillespie 42). These practices reveal that algorithmic moderation and corporate interests are intertwined, undermining the original promise of social media. Such practices demonstrate that corporate control over information flow is not incidental but foundational to the design of modern social media itself. Understanding social media’s transformation from open communication spaces to curated environments driven by profit is essential to recognizing why regulation and cultural resistance are both necessary.

### Regulation Efforts

Recognizing the dangers posed by corporate-controlled social media, lawmakers have pursued regulatory efforts intended to curb the most harmful practices, but these attempts have largely fallen short of addressing the systemic issues. Across the United States, various states have passed laws designed to promote transparency and accountability in online platforms. For example, California’s AB 587 requires companies to disclose their content moderation policies, while Texas’s HB20 seeks to limit social media companies’ ability to remove certain types of political speech. However, as Robert Gorwa, a social science researcher and graduate of the University of Oxford, explains in The Politics of Platform Regulation, these state-level laws often face significant constitutional challenges and court interventions that prevent meaningful enforcement (Gorwa 115). At the federal level, regulation efforts have also stalled due to deep political divisions, with Democrats pushing for stronger moderation against misinformation and Republicans advocating for fewer restrictions in the name of free speech (Gorwa 112). One major federal obstacle to effective regulation is Section 230 of the Communications Decency Act, a 1996 law that shields online platforms from liability for user-generated content. Originally intended to foster innovation and free expression, Section 230 now serves as a structural barrier to accountability in an era of algorithmically curated media. Tarleton Gillespie explains that Section 230 provides platforms with a “safe harbor,” allowing them to moderate—or ignore—content as they see fit without legal repercussions, giving them the “right but not the responsibility” to shape online discourse (Gillespie 30). Moreover, Gorwa emphasizes that existing regulatory bodies like the FTC and FCC lack the power and resources needed to effectively govern large technology platforms (Gorwa 117–118). Although these regulatory initiatives reflect growing awareness of social media’s harms, their limited scope and fractured implementation demonstrate that regulation alone cannot dismantle the profit-driven architecture of corporate social media platforms.

### Epistemic Warfare

Beyond commercial manipulation and legislative failure lies a deeper crisis: the use of social media as a battleground for epistemic warfare, which involves the deliberate undermining of shared reality through the distortion of truth and knowledge. This phenomenon reflects more than just bad information; it reveals a systemic issue in how social media platforms are designed to fragment understanding and erode users’ ability to evaluate credibility. Philosopher Margherita Mattioni argues that platforms like Facebook, TikTok, and X are “epistemically opaque,” meaning that users are systematically denied access to the mechanisms that determine what information reaches them (Mattioni). This opacity, combined with features such as algorithmic personalization, information overload, and filter bubbles, prevents users from exercising what Mattioni calls “epistemic vigilance,” which is the ability to critically assess the reliability of information and its sources (1507). These conditions do not merely allow disinformation to flourish, but they create a digital environment where truth becomes relative, and belief is shaped less by evidence than by engagement-driven algorithms. Mattioni further warns that even proposed solutions like platform labeling or user education fall short of addressing the structural causes of epistemic vulnerability (1510). While scholars have outlined these structural limitations, public awareness is also beginning to reflect growing skepticism. A 2024 Pew Research Center study found that 40% of Americans who get news from social media now cite inaccuracy as their top concern — a significant increase from 31% just five years earlier — suggesting that many users recognize the unreliability of digital information environments (Wang and Forman-Katz). The consequences of this epistemic manipulation extend beyond confusion; they contribute to a growing erosion of trust in public institutions, expertise, and even shared reality. From COVID-19 conspiracy theories to election denialism, the fragmentation of truth on social media has undermined confidence in science, journalism, and democratic processes. This breakdown of trust leaves users more vulnerable to radicalization, more resistant to corrective information, and more likely to disengage from civic life altogether. In this context, regulation focused solely on content moderation or user protection cannot resolve the deeper issue: that the architecture of social media itself now functions as a system of epistemic control.

### Resistance (and Why It’s Failing) 

In response to the growing manipulation and epistemic control exercised by mainstream platforms, several alternative models of digital communication have emerged, but they remain largely marginalized and ineffective at scale. Decentralized platforms like Mastodon, Diaspora, and Steemit promise to “re-decentralize” the web by removing corporate gatekeepers and returning control to users. However, these platforms struggle to overcome serious adoption barriers. In their WIRED article, Chelsea Barabas, Neha Narula, and Ethan Zuckerman argue that despite the idealistic appeal of decentralization, these systems face significant obstacles such as low usability, weak network effects, and poor onboarding experiences (“Decentralized Social Networks Sound Great. Too Bad They’ll Never Work”). Most people join social networks because their friends are there, not because they align with decentralist ideology. Additionally, these platforms pose technical challenges, such as managing cryptographic keys and ensuring secure identity verification, which limit their accessibility to the general public. Mattioni adds that users are already epistemically disadvantaged by design and expecting them to migrate to more demanding platforms underestimates the structural forces that shape online behavior (Mattioni 1510). Together, these factors demonstrate that while resistance efforts exist, they are technologically fragile, socially unpopular, and structurally outmatched by the scale, convenience, and addictive design of mainstream platforms. 
### Opposing Viewpoint

While social media platforms have contributed to the erosion of truth and the manipulation of public understanding, some scholars and activists argue that these same platforms have also served as powerful tools for social justice and political mobilization. Movements such as Black Lives Matter and the Ferguson protests used platforms like Twitter to share firsthand accounts, organize public demonstrations, and bypass traditional media gatekeeping. In her article for Nieman Reports, Zeynep Tufekci highlights how Twitter’s early chronological feed allowed protest messages to gain visibility, whereas Facebook’s engagement-based algorithm failed to surface the same content, favoring less disruptive and more “likable” stories (Tufekci 50). This contrast underscores the real but uneven power of social media to amplify grassroots activism. However, even Tufekci acknowledges that these moments of visibility often occur despite platform design, not because of it. As Mattioni notes, platforms are structurally aligned to reward emotional simplicity and passive consumption, not civic complexity or epistemic autonomy (Mattioni 1510). Thus, while social media can enable powerful bursts of mobilization, these are temporary exceptions within a system fundamentally oriented toward commodified engagement rather than sustained democratic discourse. Even when activist content goes viral, it often becomes diluted through trends and performative sharing, losing its potency as platforms prioritize visibility over depth. These flashpoints of awareness rarely translate into long-term structural impact within a system still governed by engagement metrics. 
### Conclusion

The definition of social media must be reevaluated considering its transformation from a platform for open communication to an engine of manipulation, fragmentation, and epistemic control. While corporate platforms promise connectivity, they operate within structures that undermine truth, prioritize profit, and erode users’ ability to make informed decisions. Scholars such as Margherita Mattioni have shown how design features like algorithmic filtering and platform opacity hinder users’ epistemic autonomy, while empirical studies confirm that even digitally literate individuals continue to share falsehoods online (Mattioni 1510; Sirlin et al.). Moreover, digital literacy efforts often assume that users have both the time and the motivation to critically assess the content they encounter, which is an assumption that rarely holds in the fast-paced, attention-fractured environment of social media. Even the most well-informed users remain vulnerable when the very platforms they rely on are designed to exploit emotional response over reflection. This suggests that although digital literacy is a critical skill, it cannot alone overcome the systemic incentives that reward misinformation and passivity. Efforts such as those led by the News Literacy Project provide accessible educational tools, but meaningful change requires more than individual awareness; it calls for sustained public pressure, ethical technology design, and a cultural shift toward valuing truth over engagement. While these initiatives are promising, they remain insufficient without broader public demand for change. A society overwhelmed by noise and profit-driven distortion cannot rely solely on personal responsibility to preserve truth. Though the path forward is unclear, confronting the limitations of social media as it currently exists is a necessary first step in reclaiming the integrity of our shared information spaces, rebuilding public trust, and reimagining the role of truth in a functioning democracy.
 
### Works Cited

Barabas, Chelsea., et al. “Decentralized Social Networks Sound Great. Too Bad They’ll Never Work.” Wired, 8 Sept. 2017, https://www.wired.com/story/decentralized-social-networks-sound-great-too-bad-theyll-never-work/. 

Forman-Katz, Luxuan Wang and Naomi. “Many Americans Find Value in Getting News on Social Media, but Concerns about Inaccuracy Have Risen.” Pew Research Center, 7 Feb. 2024, https://www.pewresearch.org/short-reads/2024/02/07/many-americans-find-value-in-getting-news-on-social-media-but-concerns-about-inaccuracy-have-risen/.

Gillespie, Tarleton. “The Myth of the Neutral Platform.” Custodians of the Internet, Yale University Press, 2018, pp. 24–44. https://doi.org/10.12987/9780300235029-002.
Gorwa, Robert. The Politics of Platform Regulation: How Governments Shape Online Content Moderation (1st ed.). Oxford University Press, 2024. https://doi.org/10.1093/oso/9780197692851.001.0001

Kellogg, Katherine C., et al. “Algorithms at Work: The New Contested Terrain of Control.” Academy of Management Annals, vol. 14, no. 1, Jan. 2020, pp. 366–410. https://doi.org/10.5465/annals.2018.0174.

Mattioni, M. (2024). Is Epistemic Autonomy Technologically Possible Within Social Media? A Socio-Epistemological Investigation of the Epistemic Opacity of Social Media Platforms: Is Epistemic Autonomy Technologically Possible Within Social Media? A Socio-Epistemological Investigation. Topoi, vol. 43, no. 5, 2024, pp.1503–16. https://doi.org/10.1007/s11245-024-10107-x

Merriam-Webster. “Definition of SOCIAL MEDIA.” Merriam-Webster.com Dictionary, Merriam-Webster, 2024, www.merriam-webster.com/dictionary/social%20media.

Sirlin, Nathaniel, Ziv Epstein, Antonio A. Arechar, and David G. Rand. Digital literacy is associated with more discerning accuracy judgments but not sharing intentions. Harvard Kennedy School Misinformation Review, vol. 2, no. 6, 2021, https://doi.org/10.37016/mr-2020-83

Sasiepre. “Download Social Media, Marketing, Social Icons. Royalty-Free Vector Graphic.” Pixabay.com, 9 Feb. 2021, pixabay.com/vectors/social-media-marketing-social-icons-5995251/. 

Tufekci, Zeynep. “How News Flows on Social Media.” Nieman Reports, vol. 71, no. 2, Apr. 2017, pp. 50-52. EBSCOhost, research.ebsco.com/linkprocessor/plink?id=e7cdcca8-6609-38ad-9ae4-bbf66eb9a43d. 
